from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

custom_prompt = PromptTemplate(
    input_variables=["context", "question"],
    template="""
××ª×” ×™×•×¢×¥ ×¨×›×‘ ××•××—×”.
×ª×¢× ×” ×¨×§ ×œ×¤×™ ×”×¡×¤×¨ ×”×•×¨××•×ª ×©××¦×•×¨×£ ×›pdf. 
×× ××™×Ÿ ×ª×©×•×‘×” ×‘×¨×•×¨×” ×‘××¡××š, ×××•×¨ '××™×Ÿ ×ª×©×•×‘×” ×‘××¡××š'.
××œ ×ª× ×—×© ×•××œ ×ª×¡×¤×§ ××™×“×¢ ×××§×•×¨×•×ª ×—×™×¦×•× ×™×™× ××• ×™×“×¢ ×›×œ×œ×™.
×©××•×¨ ×¢×œ ×©×¤×” ××§×¦×•×¢×™×ª ×•×‘×¨×•×¨×”, ×‘×œ×™ ×œ×”×•×¡×™×£ ×¤×¨×©× ×•×™×•×ª ××• ×”××œ×¦×•×ª ××™×©×™×•×ª.
×•×“× ×©×”×ª×©×•×‘×•×ª ××“×•×™×§×•×ª ×•××‘×•×¡×¡×•×ª ×¢×œ ×”×˜×§×¡×˜ ×‘×œ×‘×“.

×‘×›×œ ×ª×©×•×‘×” ×”×©×ª××© ×‘×ª×‘× ×™×ª ×”×‘××”:

âœ… ×ª×©×•×‘×” ××”×™×¨×”:
ğŸ” ×”×¡×‘×¨ ××¤×•×¨×˜:
âš ï¸ ××–×”×¨×”:
ğŸ“– ×œ××™×“×¢ × ×•×¡×£, ×¨××” ×‘×¢××•×“×™× XXâ€“XX ×•-XXâ€“XX ×‘×¡×¤×¨ ×”× ×”×’.

×”×§×©×¨:
{context}

×©××œ×”:
{question}
"""
)


def get_answer_from_index(message, book_id):
    vectorstore = FAISS.load_local(
        f"vector_store/{book_id}",
        OpenAIEmbeddings(model="text-embedding-3-large"),
        allow_dangerous_deserialization=True
    )

    qa_chain = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(model_name="gpt-4o"),
        retriever=vectorstore.as_retriever(search_kwargs={"k": 4}),
        chain_type="stuff",
        chain_type_kwargs={"prompt": custom_prompt},
        return_source_documents=True
    )

    result = qa_chain({"query": message})
    return result['result']
